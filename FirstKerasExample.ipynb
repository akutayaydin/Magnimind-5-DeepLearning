{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akutayaydin/Magnimind-5-DeepLearning/blob/main/FirstKerasExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2zLGPuW2EBe"
      },
      "source": [
        "# First NN with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPjmXGKo2EBg"
      },
      "source": [
        "### Pima Indians Onset of Diabetes Dataset (by Jason Brownlee)\n",
        "It is a standard machine learning dataset available for free download from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years. It is a binary classification problem (onset of diabetes as 1 or not as 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sD6oTae2EBh"
      },
      "source": [
        "### 1 Load Dataset and Split into Input (X) and Output (y) Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQJiWT4v2EBh",
        "outputId": "373bebd1-c0f3-4b64-c1de-bc4554144edb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from numpy import loadtxt\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9CXqgmZ2EBj",
        "outputId": "74932e88-9979-4ad3-9777-d51f408c9ca2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nNTP: Number of times pregnant.\\nPGC: Plasma glucose concentration a 2 hours in an oral glucose tolerance test. 3. Diastolic blood pressure (mm Hg).\\nTSFT: Triceps skin fold thickness (mm).\\n2hSI: 2-Hour serum insulin (mu U/ml).\\nBMI: Body mass index.\\nDPF: Diabetes pedigree function.\\nAge: Age (years).\\nOnDiab: Class, onset of diabetes within five years.\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the dataset\n",
        "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
        "dataset = pd.read_csv('diabetes.csv')\n",
        "dataset.columns = ['NTP', 'PGC','DBP','TSFT','2hSI','BMI','DPF','Age','OnDiab']\n",
        "\n",
        "\"\"\"\n",
        "NTP: Number of times pregnant.\n",
        "PGC: Plasma glucose concentration a 2 hours in an oral glucose tolerance test. 3. Diastolic blood pressure (mm Hg).\n",
        "TSFT: Triceps skin fold thickness (mm).\n",
        "2hSI: 2-Hour serum insulin (mu U/ml).\n",
        "BMI: Body mass index.\n",
        "DPF: Diabetes pedigree function.\n",
        "Age: Age (years).\n",
        "OnDiab: Class, onset of diabetes within five years.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RygGBMx32EBk",
        "outputId": "20384a2e-9d52-4d25-fd25-ab43e4c1ce08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NTP</th>\n",
              "      <th>PGC</th>\n",
              "      <th>DBP</th>\n",
              "      <th>TSFT</th>\n",
              "      <th>2hSI</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DPF</th>\n",
              "      <th>Age</th>\n",
              "      <th>OnDiab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NTP  PGC  DBP  TSFT  2hSI   BMI    DPF  Age  OnDiab\n",
              "0    1   85   66    29     0  26.6  0.351   31       0\n",
              "1    8  183   64     0     0  23.3  0.672   32       1\n",
              "2    1   89   66    23    94  28.1  0.167   21       0\n",
              "3    0  137   40    35   168  43.1  2.288   33       1\n",
              "4    5  116   74     0     0  25.6  0.201   30       0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgzWIWYQ2EBk",
        "outputId": "5d724719-f2d2-4d2a-9c1f-bc2e084add73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(767, 9)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkS7V3u02EBl"
      },
      "outputs": [],
      "source": [
        "# split into input (X) and output (y) variables\n",
        "X = dataset.drop(\"OnDiab\",axis=1)\n",
        "y = dataset[\"OnDiab\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRT_3wML2EBl",
        "outputId": "6840bd80-9439-4e2a-f9d5-db14ea853793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tYJ3Ivz2EBm"
      },
      "source": [
        "### 2 Define the Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQpxWDu12EBm"
      },
      "source": [
        "Models in Keras are defined as a sequence of layers. We create a Sequential model and add layers one at a time until we are happy with our network topology. The first thing to get right is to ensure the input layer has the right number of inputs. This can be specified when creating the first layer with the input dim argument and setting it to 8 for the 8 input variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcKJKbbf2EBn"
      },
      "source": [
        "Fully connected layers are defined using the Dense class. We can specify the number of neurons in the layer as the first argument and specify the activation function using the activation argument. We will use the rectifier (relu) activation function on the first two layers and the sigmoid activation function in the output layer. We use a sigmoid activation function on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzROh_UE2EBn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV7bLSXl2EBn"
      },
      "source": [
        "### 3 Compile the Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrhocFJZ2EBn"
      },
      "source": [
        "Compiling the model uses the efficient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow. The backend automatically chooses the best way to represent the network for training and making predictions to run on your hardware. When compiling, we must specify some additional properties required when training the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flChexbx2EBn"
      },
      "source": [
        "We must specify the loss function to use to evaluate a set of weights, the optimizer used to search through different weights for the network and any optional metrics we would like to collect and report during training.\n",
        "\n",
        "In this case we will use logarithmic loss, which for a binary classification problem is defined in Keras as binary crossentropy. We will also use the efficient gradient descent algorithm adam for no other reason that it is an efficient default.\n",
        "\n",
        "Finally, because it is a classification problem, we will collect and report the classification accuracy as the metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLMVtd7S2EBn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsJF-9402EBo"
      },
      "source": [
        "### 4 Fit Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462S6XKn2EBo"
      },
      "source": [
        "We can train or fit our model on our loaded data by calling the `fit()` function on the model. The training process will run for a fixed number of iterations through the dataset called epochs, that we must specify using the epochs argument. We can also set the number of instances that are evaluated before a weight update in the network is performed called the batch size and set using the batch size argument. For this problem we will run for a small number of epochs (150) and use a relatively small batch size of 16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYYkswlL2EBo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GMlP7Zc2EBo"
      },
      "source": [
        "### 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33s6mu3Q2EBo"
      },
      "source": [
        "You can evaluate your model on your training dataset using the `evaluation()` function on your model and pass it the same input and output used to train the model. This will generate a prediction for each input and output pair and collect scores, including the average loss and any metrics you have configured, such as accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuajTGZt2EBo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qux-6U252EBo"
      },
      "source": [
        "### 6 Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhQX2L122EBo"
      },
      "source": [
        "Making predictions is as easy as calling the `predict()` function on the model. We are using a sigmoid activation function on the output layer, so the predictions will be a probability in the range between 0 and 1. We can easily convert them into a crisp binary prediction for this classification task by rounding them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23rYEzwv2EBp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tia6x2iY2EBp"
      },
      "source": [
        "### 7 Use a Automatic Verification Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtoxXMD_2EBp"
      },
      "source": [
        "Keras can separate a portion of your training data into a validation dataset and evaluate the performance of your model on that validation dataset each epoch. You can do this by setting the validation split argument on the `fit()` function to a percentage of the size of your training dataset.\n",
        "\n",
        "Running the example below, you can see that the verbose output on each epoch shows the loss and accuracy on both the training dataset and the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M9jZKKm2EBp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0ykZc62EBp"
      },
      "source": [
        "### 8 Use a Manual Verification Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjE5kxgR2EBp"
      },
      "source": [
        "Keras also allows you to manually specify the dataset to use for validation during training. In this example we use the handy `train_test_split()` function from the Python scikit-learn machine learning library to separate our data into a training and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3tQ2aXQ2EBp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZPFn0G12EBp"
      },
      "source": [
        "### 9 Manual *k*-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pIvf6yu2EBq"
      },
      "source": [
        "Cross-validation is often not used for evaluating deep learning models because of the greater computational expense. For example *k*-fold cross-validation is often used with 5 or 10 folds. As such, 5 or 10 models must be constructed and evaluated, greatly adding to the evaluation time of a model. Nevertheless, when the problem is small enough or if you have sufficient compute resources, *k*-fold cross-validation can give you a less biased estimate of the performance of your model.\n",
        "\n",
        "In the example below we use the handy `StratifiedKFold` class from the scikit-learn Python machine learning library to split up the training dataset into 10 folds. The folds are stratified, meaning that the algorithm attempts to balance the number of instances of each class in each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "557Fv3Ym2EBq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOqfpoaM2EBq"
      },
      "source": [
        "### 9 Use Keras Models With Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J41sqLg2EBq"
      },
      "source": [
        "The Keras library provides a convenient wrapper for deep learning models to be used as classification or regression estimators in scikit-learn. In the next sections we will work through examples of using the `KerasClassifier` wrapper for a classification neural network created in Keras and used in the scikit-learn library.\n",
        "\n",
        "The `KerasClassifier` and `KerasRegressor` classes in Keras take an argument `build_fn` which is the name of the function to call to create your model. You must define a function called whatever you like that defines your model, compiles it and returns it. In the example below we define a function `create_model()` that creates a simple multilayer neural network for the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLmncZM2EBq"
      },
      "source": [
        "#### 9.1 Evaluate Models with Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEqkEi6Z2EBq"
      },
      "source": [
        "#### 9.2 Grid Search Deep Learning Model Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUKIqzlx2EBq"
      },
      "source": [
        "After creating our model, we define arrays of values for the parameter we wish to search, specifically:\n",
        "- Optimizers for searching different weight values.\n",
        "- Initializers for preparing the network weights using different schemes.\n",
        "- Number of epochs for training the model for different number of exposures to the training dataset.\n",
        "- Batches for varying the number of samples before weight updates.\n",
        "\n",
        "The options are specified into a dictionary and passed to the configuration of the `GridSearchCV` scikit-learn class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO_XnGXP2EBr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}